{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOmLbY_n1eJd",
        "outputId": "22f1e626-4e3e-4a06-ffcb-1692bbcd068b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# every package has to install each time googlecolab runs jyputernoot book.\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = spark.read.csv('/content/customer_segmentation_dataset.csv',inferSchema=True, header =True)\\\n",
        ".toDF(\"age\",\"annual_income\",\"spending_score\",\"years_as_customer\",\"number_of_purchases\",\"customer_segment\")\n",
        "\n",
        "\n",
        "dataset.select('customer_segment').distinct().show(10)\n",
        "dataset.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPI6oHMn2o9D",
        "outputId": "4fde6207-0dab-4e0d-e0be-ca5342172724"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|customer_segment|\n",
            "+----------------+\n",
            "|    Medium Value|\n",
            "|      High Value|\n",
            "|       Low Value|\n",
            "+----------------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "vector_assembler = VectorAssembler(\\\n",
        "inputCols=[\"age\",\"annual_income\",\"spending_score\",\"years_as_customer\",\"number_of_purchases\"],\\\n",
        "outputCol=\"features\")\n",
        "df_temp = vector_assembler.transform(dataset)\n",
        "df_temp.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XoQuf2a4WRB",
        "outputId": "c5c9137d-fab3-4d34-e548-bd7832da5844"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+--------------+-----------------+-------------------+----------------+--------------------+\n",
            "|age|annual_income|spending_score|years_as_customer|number_of_purchases|customer_segment|            features|\n",
            "+---+-------------+--------------+-----------------+-------------------+----------------+--------------------+\n",
            "| 22|       113441|            19|                2|                 44|       Low Value|[22.0,113441.0,19...|\n",
            "| 47|        85415|            74|                7|                 11|    Medium Value|[47.0,85415.0,74....|\n",
            "| 60|        78075|            18|               19|                 37|       Low Value|[60.0,78075.0,18....|\n",
            "+---+-------------+--------------+-----------------+-------------------+----------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Letâ€™s remove unnecessary columns:\n",
        "df = df_temp.drop(\"age\",\"annual_income\",\"spending_score\",\"years_as_customer\",\"number_of_purchases\")\n",
        "df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LffdfSyd45eh",
        "outputId": "600d6e41-19d1-4441-9994-95b773be9347"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+\n",
            "|customer_segment|            features|\n",
            "+----------------+--------------------+\n",
            "|       Low Value|[22.0,113441.0,19...|\n",
            "|    Medium Value|[47.0,85415.0,74....|\n",
            "|       Low Value|[60.0,78075.0,18....|\n",
            "+----------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "l_indexer = StringIndexer(inputCol='customer_segment', outputCol=\"customerIndex\")\n",
        "df = l_indexer.fit(df).transform(df)\n",
        "\n",
        "\n",
        "df.select('customer_segment','customerIndex').distinct().show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esAvfpP16PXn",
        "outputId": "2d812c02-3d6e-4fa6-9344-9f4136d00a3d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------+\n",
            "|customer_segment|customerIndex|\n",
            "+----------------+-------------+\n",
            "|      High Value|          2.0|\n",
            "|    Medium Value|          1.0|\n",
            "|       Low Value|          0.0|\n",
            "+----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])"
      ],
      "metadata": {
        "id": "IkE2v80U7YR3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "dt = DecisionTreeClassifier(labelCol=\"customerIndex\", featuresCol=\"features\",impurity='entropy', maxDepth=4,seed=1234)\n",
        "model = dt.fit(trainingData)\n",
        "predictions = model.transform(testData)"
      ],
      "metadata": {
        "id": "hgpyS__N7du-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"customerIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test accuracy =  \" , accuracy)\n",
        "print(model.toDebugString)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPsDhZJo7rmW",
        "outputId": "d2ffe2f8-0657-477a-cbda-9993c31cd425"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   0.9797119053856307\n",
            "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_4fc53bec05c9, depth=2, numNodes=5, numClasses=3, numFeatures=5\n",
            "  If (feature 2 <= 49.5)\n",
            "   Predict: 0.0\n",
            "  Else (feature 2 > 49.5)\n",
            "   If (feature 2 <= 74.5)\n",
            "    Predict: 1.0\n",
            "   Else (feature 2 > 74.5)\n",
            "    Predict: 2.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is code for multiple classification using logistic Regression\n",
        "from pyspark.ml.classification import OneVsRest\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
        "lr = LogisticRegression(maxIter=100, \\\n",
        "\n",
        "                        featuresCol=\"features\", \\\n",
        "\n",
        "                        labelCol='customerIndex')\n",
        "ovr = OneVsRest(classifier=lr, \\\n",
        "                labelCol='customerIndex', \\\n",
        "                featuresCol='features')\n",
        "#from pyspark.ml import Pipeline\n",
        "#pipeline_ovr = Pipeline(stages=[vecAssembler, stdScaler, ovr])\n",
        "#pipelineModel_ovr = pipeline_ovr.fit(trainDF)\n",
        "\n",
        "ovrModel = ovr.fit(train)\n",
        "predictionsovr = ovrModel.transform(test)\n",
        "\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\\\n",
        "labelCol=\"customerIndex\", predictionCol=\"prediction\",\\\n",
        "metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictionsovr)\n",
        "print(\"Test accuracy =  \" , accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlfXVyef8ZdO",
        "outputId": "1c345400-b817-438c-998f-64c194d96fc9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy =   1.0\n"
          ]
        }
      ]
    }
  ]
}